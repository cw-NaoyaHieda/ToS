---
title: "市場リスク評価"
author: "Naoya Hieda"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    number_sections: yes
    css: "toc.css"
    toc_depth: 2
    pandoc_args: [
        "--from", "markdown+autolink_bare_uris+tex_math_single_backslash-implicit_figures"
        ]
---


```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
	             prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE,
               fig.width=12,
               fig.height=9)
opts_knit$set(width=75)
set.seed(2017)
```


```{r package}
#実験で使う関数
source("script/functions.R")
objects()
#パッケージのインストールと読み込み
#持ってないパッケージはインストールする
targetPackages <- c('zoo', 'xts','Quandl',
                    'quantmod','ggplot2','grid','reshape2','scales',
                    'dplyr','moments','xtable','gridExtra','snow','parallel') 
newPackages <- targetPackages[!(targetPackages %in% installed.packages()[,"Package"])]
if(length(newPackages)) install.packages(newPackages, repos = "http://cran.us.r-project.org")
for(package in targetPackages) library(package, character.only = T)
```

# 株価収益率の分析

```{r n225}
#データの読み込み
n225 <- read.csv("data/nikkei225.csv",skip=1)
y <- NULL
#終値(1日の最後の値段)を使う
y$Close <- n225$PX_LAST
#日付データをDate型に変換
y$ymd <- as.POSIXct(n225$Date)
#データフレームにする(行列の列に名前がついているもの)
#ggplotはdata.frameのデータにしか使えないので注意
df <-data.frame(dt=y$ymd, x=y$Close)
```

## 日経225<br>平均株価指数の遷移

```{r fig1}
#ggplotで日経平均株価をplot
#ggplotの各関数の意味は自分で調べること
ggplot(df,aes(x=dt,y=x))+geom_line()+
        scale_x_datetime(breaks = date_breaks("6 months"))+
        labs(y="N225")+
        theme_bw()
```

## 日経平均の<br>対数収益率の推移

```{r fig2}
#日経平均の対数収益率をplot
df$log_x <- c(NA,diff(log(df$x))*100)
ggplot(df[-1,],aes(dt,log_x))+geom_line()+
        scale_x_datetime(breaks = date_breaks("6 months"))+
        labs(y="log return")+
        theme_bw()+
        theme(strip.background = element_blank(),
              panel.border = element_rect(colour = "black"))
```

# 最尤推定

## 尺度変換した<br>sinh-arcsinh分布の<br>パラメータ推定

```{r MLE}
rt <- df$log_x[-1]
rt <- rt[rt!=0]
fit <- mle.dfas2(rt, ini=c(0, log(0.2), -0.2, 0.5))

fit$par2

df= data.frame(log_return=rt)
ggplot(df, aes(log_return))+
        geom_histogram(binwidth=.3, colour="black", fill="white",
                          aes(y=..density..))+
      #scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")+
       xlim(min(rt),max(rt))+
       stat_function(fun=dnorm,
                         #colour="violetred",
                         aes(colour ="Normal distribution"),
                         size=1,
                         n=401,
                         args=list(mean=mean(rt), sd = sd(rt)))+
       stat_function(fun=dfas2,
                         #colour="green",
                         aes(colour ="Tos sinh-arcsinh distribution"),
                         size=1,
                         n=401,
                         args=list(mu=fit$par2[1],
                                  sigma = fit$par2[2],
                                  lambda = fit$par2[3],
                                  delta = fit$par2[4]))+
        theme_bw()+
  theme(legend.position = "bottom")
```


## モーメントの計算

```{r moments}
# パラメータが与えられた時のFA分布について
out.mom <- fas2.moment(fit$par2)
# 表にする
hyou.a <- matrix(0, 3,4)
hyou.a[1,] <- c( mean(rt), sd(rt), skewness(rt), kurtosis(rt))
hyou.a[2,] <- c( mean(rt), sd(rt), 0, 3)
hyou.a[3,] <- c(out.mom$m1, sqrt(out.mom$v2), out.mom$b1, out.mom$b2)
dimnames(hyou.a) <- list( c("sample","N","FSA"), c("E(X)", "sqrt Var(X)", "beta1", "beta2"))
print(xtable(hyou.a, digits=3))
hyou.a
```


# sinh-arcsinh分布からの<br>　乱数生成<br>　(重点サンプリング)

```{r sinh-arcsin_r}
library(parallel)
cl <- makeCluster(25, type="SOCK")
cl_l <- length(cl)
clusterExport(cl,list("s_inverse","dfas","Cf","Sf","cl_l","fit"))
rand.fa<-rfa_SIR_para(n=10000, mu=fit$par2[1],
                                  sigma = fit$par2[2],
                                  lambda = fit$par2[3],
                                  delta = fit$par2[4])

ggplot()+geom_histogram(data=data.frame(sample=rand.fa$q),aes(x=sample),
                        binwidth = 14/100)+theme_bw()

## 実際の分布との<br>比較

df <-data.frame(x=rand.fa$q)
f2 <- ggplot(df,aes(x=x))+
        geom_histogram(aes(y=..density.., fill=..count..),
          binwidth = .15, colour="black") +xlab("log return")+
         scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")+
        theme_bw()+
        theme(#panel.grid.major = element_blank(),
        #panel.grid.minor = element_blank(),
        strip.background = element_blank(),
        panel.border = element_rect(colour = "black"),
        legend.title=element_blank(),legend.position="none")+
        stat_function(fun=dfas2,
                         #colour="violetred",
                         aes(colour ="red"),
                         size=1,
                         n=401,
                         args=list(mu=fit$par2[1],
                                  sigma = fit$par2[2],
                                  lambda = fit$par2[3],
                                  delta = fit$par2[4]))

f2
stopCluster(cl)
```



# FA分布の<br>　VaRとESの計算

$\alpha=0.01, 0.025, 0.05$にしてVaRとESを推定する. 


```{r vares2}
## 真値を計算
#99%,97.5%,95%の各点に対して，先ほどの関数を用いて求める
VaR1.fa <- qfas(0.01, mu=fit$par2[1], sigma=fit$par2[2],
                lambda=fit$par2[3], delta = fit$par2[4])
VaR25.fa <- qfas(0.025, mu=fit$par2[1], sigma=fit$par2[2],
                 lambda=fit$par2[3], delta = fit$par2[4])
VaR5.fa <- qfas(0.05, mu=fit$par2[1], sigma=fit$par2[2],
                lambda=fit$par2[3], delta = fit$par2[4])
#まとめておく
VaR.true.FA <- c(VaR1.fa ,VaR25.fa ,VaR5.fa )

ES1.fa <- find.ES(p=0.01, par=fit$par2)
ES25.fa <- find.ES(p=0.025, par=fit$par2)
ES5.fa <- find.ES(p=0.05, par=fit$par2)
#まとめる
ES.true.FA <- c(ES1.fa ,ES25.fa ,ES5.fa )
ES.true.FA
```

```{r}
library(parallel)
cl <- makeCluster(25, type="SOCK")
cl_l <- length(cl)
clusterExport(cl,list("s_inverse","dfas","Cf","Sf","cl_l","fit"))
## 単純<br>モンテカルロ法

SMC.fa.out <- SMC.fa(fit$par2)
```

```{r}
library(parallel)
cl <- makeCluster(25, type="SOCK")
cl_l <- length(cl)
clusterExport(cl,list("s_inverse","dfas","Cf","Sf","cl_l","fit"))

## IS(重点サンプリング)による<br>VaRとESを計算

# 99%,97.5%,95%それぞれのVaRと平均が一致するthetaを取得
theta.val1<- find.theta(0.01, fit$par2)
theta.val25<- find.theta(0.025, fit$par2)
theta.val5<- find.theta(0.05, fit$par2)



# 密度関数の確認
dx <- seq(-30,10,length=200)
out1 <- sapply(dx, d.IS, theta=theta.val1, par=fit$par2)
out25 <- sapply(dx, d.IS, theta=theta.val25, par=fit$par2)
out5 <- sapply(dx, d.IS, theta=theta.val5, par=fit$par2)
out <- cbind(out1,out25,out5)
#matplot(dx,out,type="l",lwd=2)
ggplot(data.frame(dx,out) %>% melt('dx'),
       aes(x=dx,y=value,colour=variable))+
  geom_line(size=2)+theme_bw()+
  theme(legend.position = "bottom")

clusterExport(cl,list("VaR.true.FA","dfas2"))

rfa.IS.1<-rIS_SIR(n=20000, par=fit$par2, par2=VaR.true.FA[1], theta=theta.val1)

1/sum(rfa.IS.1$w^2)

rfa.IS.25<-rIS_SIR(n=20000, par=fit$par2, par2=VaR.true.FA[2], theta=theta.val25)

1/sum(rfa.IS.25$w^2)

rfa.IS.5<-rIS_SIR(n=20000, par=fit$par2, par2=VaR.true.FA[3], theta=theta.val5)

1/sum(rfa.IS.5$w^2)

# サンプリングしたものを入力としてFA分布の重点サンプリングを行う
rfa1 <- sample(rfa.IS.1$q, 10000)
rfa25 <- sample(rfa.IS.25$q, 10000)
rfa5 <- sample(rfa.IS.5$q, 10000)
clusterExport(cl,list("rfa1","rfa25","rfa5"))
out.fa <- IS.fa_check_weigth()

1/sum(out.fa[[1]]^2)
1/sum(out.fa[[2]]^2)
1/sum(out.fa[[3]]^2)

stopCluster(cl)
```


```{r}
cl <- makeCluster(25, type="SOCK")
cl_l <- length(cl)
clusterExport(cl,list("s_inverse","dfas","Cf","Sf",
                      "cl_l","fit","VaR.true.FA","dfas2"))

check_weight <-c()
for(i in 1:10){
  rfa.IS.1<-rIS_SIR(n=20000, par=fit$par2, par2=VaR.true.FA[1], theta=theta.val1)
  rfa.IS.25<-rIS_SIR(n=20000, par=fit$par2, par2=VaR.true.FA[2], theta=theta.val25)
  rfa.IS.5<-rIS_SIR(n=20000, par=fit$par2, par2=VaR.true.FA[3], theta=theta.val5)
  # サンプリングしたものを入力としてFA分布の重点サンプリングを行う
  rfa1 <- sample(rfa.IS.1$q, 10000)
  rfa25 <- sample(rfa.IS.25$q, 10000)
  rfa5 <- sample(rfa.IS.5$q, 10000)
  clusterExport(cl,list("rfa1","rfa25","rfa5"))
  out.fa <- IS.fa_check_weigth()
  
  check_weight<- rbind(check_weight,
  data.frame(w1=1/sum(out.fa[[1]]^2),w25=1/sum(out.fa[[2]]^2),w5=1/sum(out.fa[[3]]^2)))
}
stopCluster(cl)
check_weight
```